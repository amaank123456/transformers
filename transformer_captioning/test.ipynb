{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base dir  /Users/amaankazi/Library/CloudStorage/OneDrive-Personal/CMU/Fall_2024/VLR/hw3/transformers/transformer_captioning/datasets/coco_captioning\n",
      "base dir  /Users/amaankazi/Library/CloudStorage/OneDrive-Personal/CMU/Fall_2024/VLR/hw3/transformers/transformer_captioning/datasets/coco_captioning\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import * \n",
    "from torch.utils.data import DataLoader\n",
    "from trainer import Trainer\n",
    "from transformer import TransformerDecoder\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "set_all_seeds(42) ### DO NOT CHANGE THIS LINE\n",
    "exp_name = 'case1'\n",
    "\n",
    "train_dataset = CocoDataset(load_coco_data(max_train=1024), 'train')\n",
    "train_dataloader =  DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "val_dataset = CocoDataset(load_coco_data(max_val = 1024), 'val')\n",
    "val_dataloader =  DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, captions = next(iter(train_dataloader))[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerDecoder(\n",
    "          word_to_idx=train_dataset.data['word_to_idx'],\n",
    "          idx_to_word = train_dataset.data['idx_to_word'],\n",
    "          input_dim=train_dataset.data['train_features'].shape[1],\n",
    "          embed_dim=256,\n",
    "          num_heads=2,\n",
    "          num_layers=2,\n",
    "          max_length=30,\n",
    "          device = 'cpu'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = transformer(features, captions[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[:, 1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 1004])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1004])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_mask = captions[:, 1:].clone()\n",
    "null_mask[null_mask != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9891, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.cross_entropy(logits.permute(0,2,1), captions[:, 1:], reduction='none')*null_mask).sum() / null_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1004, 16])\n"
     ]
    }
   ],
   "source": [
    "pred = torch.randn(captions.shape[0], len(train_dataset.data['word_to_idx']), 16)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [64, 1004], got [64, 16]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptions\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cmu16824hw3/lib/python3.10/site-packages/torch/nn/functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [64, 1004], got [64, 16]"
     ]
    }
   ],
   "source": [
    "F.cross_entropy(pred, captions[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.data['idx_to_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a train at the station and people waiting <END>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_captions(captions[0, 1:], train_dataset.data['idx_to_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-8.1785e-01,        -inf,        -inf],\n",
       "          [-1.0307e+00,  1.3950e-01,        -inf],\n",
       "          [-1.9320e-01,  1.6478e+00,  2.0532e+00]],\n",
       "\n",
       "         [[ 2.1385e+00,        -inf,        -inf],\n",
       "          [-1.2400e+00,  6.0757e-01,        -inf],\n",
       "          [ 1.2300e+00,  4.1352e-01, -2.0788e+00]],\n",
       "\n",
       "         [[ 3.1992e-01,        -inf,        -inf],\n",
       "          [-1.7017e+00, -5.5890e-01,        -inf],\n",
       "          [-8.5494e-01,  1.7058e+00, -2.2926e+00]],\n",
       "\n",
       "         [[ 6.2440e-01,        -inf,        -inf],\n",
       "          [-1.6899e+00,  1.2521e+00,        -inf],\n",
       "          [ 1.7442e-01,  2.2667e+00,  1.1365e+00]]],\n",
       "\n",
       "\n",
       "        [[[-8.3528e-01,        -inf,        -inf],\n",
       "          [ 9.0916e-01,  2.0245e+00,        -inf],\n",
       "          [-1.5483e-01,  8.1935e-01, -6.6048e-01]],\n",
       "\n",
       "         [[-2.5179e-02,        -inf,        -inf],\n",
       "          [ 1.6319e+00,  8.0117e-02,        -inf],\n",
       "          [-1.1245e+00,  5.7221e-01, -8.3986e-01]],\n",
       "\n",
       "         [[-3.7683e-01,        -inf,        -inf],\n",
       "          [ 6.6436e-01, -3.1823e-01,        -inf],\n",
       "          [ 4.1677e-01, -7.6077e-01,  3.5482e-01]],\n",
       "\n",
       "         [[-1.6462e-01,        -inf,        -inf],\n",
       "          [-1.0678e+00,  4.4851e-01,        -inf],\n",
       "          [-1.3925e+00, -1.9783e+00, -1.3666e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3587e-01,        -inf,        -inf],\n",
       "          [-1.9419e+00,  1.2981e+00,        -inf],\n",
       "          [-1.0483e-01,  8.0682e-01,  2.7744e-01]],\n",
       "\n",
       "         [[-3.7531e-01,        -inf,        -inf],\n",
       "          [ 1.1377e+00, -3.0650e-01,        -inf],\n",
       "          [-1.0063e+00, -6.7184e-01,  8.8406e-01]],\n",
       "\n",
       "         [[ 1.3204e+00,        -inf,        -inf],\n",
       "          [-1.0309e+00, -5.9583e-01,        -inf],\n",
       "          [-5.4617e-01, -1.0340e+00,  3.5754e-01]],\n",
       "\n",
       "         [[ 7.1820e-01,        -inf,        -inf],\n",
       "          [-4.9365e-01, -5.9920e-01,        -inf],\n",
       "          [-1.3134e+00, -7.4341e-01,  1.2596e+00]]],\n",
       "\n",
       "\n",
       "        [[[-2.9967e-01,        -inf,        -inf],\n",
       "          [ 3.0241e-01, -7.6058e-02,        -inf],\n",
       "          [-3.4594e-01, -1.3345e-01, -1.6083e-01]],\n",
       "\n",
       "         [[-4.0949e-01,        -inf,        -inf],\n",
       "          [ 6.3516e-05,  1.2022e+00,        -inf],\n",
       "          [-3.3083e-01,  1.9423e+00, -1.2678e+00]],\n",
       "\n",
       "         [[ 1.8827e-01,        -inf,        -inf],\n",
       "          [-4.0170e-01, -1.4667e+00,        -inf],\n",
       "          [ 3.4458e-01,  9.7850e-01, -1.0686e+00]],\n",
       "\n",
       "         [[ 1.0477e+00,        -inf,        -inf],\n",
       "          [ 5.7811e-01, -1.5643e+00,        -inf],\n",
       "          [ 3.1507e-01, -3.9962e-01,  3.1819e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1796e-01,        -inf,        -inf],\n",
       "          [ 5.0043e-01,  8.3154e-01,        -inf],\n",
       "          [-8.4998e-01,  8.9146e-01,  1.7385e+00]],\n",
       "\n",
       "         [[ 3.3477e-01,        -inf,        -inf],\n",
       "          [ 5.4674e-01,  2.1072e-01,        -inf],\n",
       "          [-1.8497e-01, -7.0120e-01, -2.1999e-02]],\n",
       "\n",
       "         [[-2.0374e+00,        -inf,        -inf],\n",
       "          [-1.0788e+00, -4.0249e-01,        -inf],\n",
       "          [ 1.2031e+00, -1.8973e+00, -7.2650e-02]],\n",
       "\n",
       "         [[-8.8659e-01,        -inf,        -inf],\n",
       "          [ 3.8809e-01, -1.0910e+00,        -inf],\n",
       "          [ 7.8654e-02, -8.0643e-01, -3.2346e-01]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(3, 3, requires_grad=False), diagonal=1) != 0\n",
    "# mask = mask.view(1,1,3,3)\n",
    "a = torch.randn(5,4,3,3)\n",
    "a.masked_fill(mask, -torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tril(): argument 'input' (position 1) must be Tensor, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtril\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: tril(): argument 'input' (position 1) must be Tensor, not int"
     ]
    }
   ],
   "source": [
    "torch.ones(3,3).tril()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf],\n",
       "        [0., 0., -inf],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.ones(3,3)*-torch.inf).triu(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmu16824hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
